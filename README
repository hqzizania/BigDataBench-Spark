BigDataBench-Spark is an integrated part of the open source big data benchmark suite project: BigDataBench, publicly available from: http://prof.ict.ac.cn/BigDataBench

If you need a citation for BigDataBench-Spark, please cite the following
paper:

[BigDataBench: a Big Data Benchmark Suite from Internet Services.](http://prof.ict.ac.cn/BigDataBench/wp-content/uploads/2013/10/Wang_BigDataBench.pdf)

Lei Wang, Jianfeng Zhan, ChunjieLuo, Yuqing Zhu, Qiang Yang, Yongqiang He,
WanlingGao, Zhen Jia, Yingjie Shi, Shujie Zhang, Cheng Zhen, Gang Lu, Kent
Zhan, Xiaona Li, and BizhuQiu. The 20th IEEE International Symposium On High
Performance Computer Architecture (HPCA-2014), February 15-19, 2014,
Orlando, Florida, USA.


This version is for Spark-0.8.0-incubating.

How to use BigDataBench's Spark workloads?

Compile the source code or download a pre-build package. For compiling, please refer to: how-to-compile.txt

Preparations:
Make sure Spark-0.8.0-incubating has been successfully installed.
Configure you bash environment:
  $SPARK_HOME points to the path where spark installed;
  Add $SPARK_HOME/bin to the $PATH variable.

The workloads inculde:
  Sort, Grep, Word Count, BayesClassifier, ConnectedComponent, PageRank


How to run:
Sort
    run:
    ./run-bigdatabench cn.ac.ict.bigdatabench.Sort2 <master> <data_file> <save_file> [<slices>]
    
    parameters:
    <master>: URL of Spark server, for example: spark://172.16.1.39:7077
    <data_file>: the HDFS path of input data, for example: /test/data.txt
    <save_file>: the HDFS path to save the result
    [<slices>]: optional, times of number of workers
    
    input data format:
    ordinary text files
    

  Grep
    run:
    ./run-bigdatabench cn.ac.ict.bigdatabench.Grep <master> <data_file> <keyword> <save_file> [<slices>]
    
    <master>: URL of Spark server, for example: spark://172.16.1.39:7077
    <data_file>: the HDFS path of input data, for example: /test/data.txt
    <keyword>: the keyword to filter the text
    <save_file>: the HDFS path to save the result
    [<slices>]: optional, times of number of workers
      
    input data format:
    ordinary text files
    

  WordCount
    run:
    ./run-bigdatabench cn.ac.ict.bigdatabench.WordCount <master> <data_file> <save_file> [<slices>]
    
    parameters:
    <master>: URL of Spark server, for example: spark://172.16.1.39:7077
    <data_file>: the HDFS path of input data, for example: /test/data.txt
    <save_file>: the HDFS path to save the result
    [<slices>]: optional, times of number of workers
    
    input data format:
    ordinary text files
    

  NaiveBayes(Training)
    run:
    ./run-bigdatabench cn.ac.ict.bigdatabench.NaiveBayes <master> <data_file> <save_file> [<slices>]
      
    parameters:
    <master>: URL of Spark server, for example: spark://172.16.1.39:7077
    <data_file>: the HDFS path of input data, for example: /test/data.txt
    <save_file>: the HDFS path to save the result
    [<slices>]: optional, times of number of workers
    
    input data format:
    classname text_content
      
      for example: (class: dog/cat)
      dog Dogs are awesome, cats too. I love my dog
      cat Cats are more preferred by software developers. I never could stand cats. I have a dog
      dog My dog's name is Willy. He likes to play with my wife's cat all day long. I love dogs
      cat Cats are difficult animals, unlike dogs, really annoying, I hate them all
      

  ConnectedComponent
    run:
    ./run-bigdatabench cn.ac.ict.bigdatabench.ConnectedComponent <master> <data_file> [<slices>]
    
    parameters:
    <master>: URL of Spark server, for example: spark://172.16.1.39:7077
    <data_file>: the HDFS path of input data, for example: /test/data.txt
    [<slices>]: optional, times of number of workers
      
    input data format:
    from_vertex to_vertex
      for example:
      1 2
      1 3
      2 5
      4 6
      6 7
      

  PageRank
    run:
    ./run-bigdatabench cn.ac.ict.bigdatabench.PageRank  <master> <file> <number_of_iterations> <save_path> [<slices>]
    
    parameters:
      <master>: URL of Spark server, for example: spark://172.16.1.39:7077
      <file>: the HDFS path of input data, for example: /test/data.txt
      <number_of_iterations>: number of iterations to run the algorithm
      <save_path>: path to save the result
      [<slices>]: optional, times of number of workers
      
    input data format
      page neighbour_page
        for example:
        a b
        a c
        b d
